---
layout: default
parent: Projects
---

              <section>
  <header class="main project">
    <strong>Project 4:</strong> Machine Learning for Image Classification
  </header>

  <p>In this project, we will use machine learning algorithms to perform <strong>image classification</strong>. Image classification is the task of predicting the class, or label, of an image out of a set of known images. This is a type of <em>supervised learning</em>, which refers to algorithms that learn a function from labelled datasets.</p>

  <p>We will be writing algorithms to do image classification on the <a href="http://yann.lecun.com/exdb/mnist/" target="_blank">MNIST</a> dataset. MNIST consists of tiny 28&#215;28 pixel images of handwritten digits from 0 to 9. A few example images from each are shown below.</p>

  <span class="image main"><img src="/assets/images/p4/mnist.png" alt="" style="max-width:550px;"/></span>

  <p>MNIST has 60,000 images to train a classification algorithm, each labelled with the correct digit. In addition, there are 10,000 images which are used for testing the accuracy of the algorithm. We will implement machine learning algorithms to classify images.</p>

  <p>
    This project is implemented using the Python programming language.
    We will be using the Python libraries NumPy and SciKit Learn.
    Before you start, make sure you have watched the <a href="/index.html#schedule_week12">Introduction to Python lecture</a>.
    There are a number of Python activities to help you practice, available on the <a href="/activities.html">Activities page</a>.
  </p>

  <p>
    The following topics are covered on this page:
  </p>

  <ul>
    <li><a href="#getting_code">Getting the Code</a>
    <li><a href="#proj_desc">Project Description</a>
      <ul>
        <li><a href="#nearest_neighbor">Part 1: Nearest Neighbors</a></li>
        <li><a href="#train_ml">Part 2: Machine Learning with SciKit Learn</a></li>
        <li><a href="#tour_guide">Part 3: Robot Museum Tour Guide</a></li>
      </ul>
    </li>
  </ul>

  <hr class="major" />

  <h2 id="getting_code">Getting the Code</h2>

  <p>
    Parts 1 and 2 of this project are completed using Jupyter Notebooks which we will run in Google Colab.
    To accept the assignment, open the template notebooks using the links provided by your instructor and select <strong>File &gt; Save a copy in Drive</strong> to save a copy in your Google Drive.
    There are two notebooks, one for each of Parts 1 and 2.
  </p>

  <p>To get the template code for Part 3 of this project, see your course page for the GitHub Classroom assignment link. Part 3 will run on the robot. Modify the LICENSE.txt file in your GitHub repository to include team member names and the year. Make sure the change is committed to your repository.
  </p>

  <ul class="todo">
    <li class="icon solid fa-laptop-code">
      <strong id="todo1">P4 License:</strong> In the file <code>LICENSE.txt</code>, replace <code>&lt;COPYRIGHT HOLDER&gt;</code> with your name. Replace <code>&lt;YEAR&gt;</code> with the current year.
    </li>
  </ul>

</section>

<section id="proj_desc">
    <header class="major">
      <h2><a href="#proj_desc">Project Description</a></h2>
    </header>

  <p>In this project, you will use various machine learning algorithms for image classification on the MNIST dataset. Then, you will use the best algorithm to perform image classification on the robot in a museum tour guide task.</p>
    <ul>
      <li><a href="#nearest_neighbor">Part 1: Nearest Neighbors in Python</a></li>
      <li><a href="#train_ml">Part 2: Training Machine Learning algorithms with SciKit Learn</a></li>
      <li><a href="#tour_guide">Part 3: Robot Museum Tour Guide</a></li>
    </ul>

  <p>
    Parts 1 and 2 are done inidivually, using Google Colab.
    We have provided a Google Colab notebook which introduces the concepts of Jupyter Notebooks and using NumPy, available as a <a href="/activities.html">practice activity</a>.
  </p>

  <h3 id="nearest_neighbor">Part 1: Nearest Neighbors</h3>

    <p>In Part 1 of this project, you will implement a Nearest Neighbor classifier. The nearest neighbor algorithm takes a test image and finds the <em>closest</em> train image, which we call the image's nearest neighbor. Then, it assigns the test image the same label as its nearest neighbor. Here is an example of some MNIST images and their nearest neighbors:</p>

    <span class="image main"><img src="/assets/images/p4/nearest_neighbor_mnist.png" alt="" style="max-width:600px;"/></span>

    <p>Open the notebook <code>Nearest Neighbors.ipynb</code> using the Google Drive link provided, and save a copy in your Drive. The notebook is made up of <em>cells</em>, which can be text cells (in Markdown) or code cells (in Python). You can run a cell by pressing the play button (<i class="fas fa-play"></i>) in the top left corner of the cell.</p>

    <p>You need to run a cell before you use anything it defines in another cell. For example, you should always run the imports cell when you start the notebook. Similarly, you must run a cell which defines a variable or function before running a cell that uses it. Start by running the import cell at the top of the notebook to import some dependencies we'll need later on.</p>

    <p>
      The text in the notebook contains descriptions of how the data is stored and how distance should be calculated. Places where you need to write code are noted in the comments, with the label <code>TODO</code>. Use the provided test cells to check that your functions are working correctly.
    </p>

    <p>
      <emph>Please read through the notebook carefully to make sure you do not miss any important instructions.</emph>
    </p>

  <h3 id="train_ml">Part 2: Training Machine Learning Algorithms</h3>

    <p>In this part, we will use a Python library called <a href="https://scikit-learn.org/stable/">SciKit Learn</a>. This library has implementations for multiple machine learning algorithms. We will focus on three of them:</p>
    <ul>
      <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">K-Nearest Neighbors</a></li>
      <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html">Linear Classifier</a></li>
      <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">Neural Network</a></li>
    </ul>

    <p>We will use the SciKit Learn implementations for each of these. Your job will be to train the best versions of the K-Nearest Neighbors and Neural Network algorithms using Cross Validation. The Linear Classifier will be used as a baseline (your Neural Network must outperform it!).</p>

    <p>
      Open the notebook <code>Machine Learning with SciKit Learn.ipynb</code> using the Google Drive link provided, and save a copy in your Drive.
      The text in the notebook guides you through each task. Places where you need to write code are noted in the comments, with the label <code>TODO</code>.
      <emph>Please read through the notebook carefully to make sure you do not miss any important instructions.</emph>
    </p>

    <p>
      The end of this notebook contains a cell which allows you to aave your favorite classification algorithm to a file.
      You should run it, then download the file for <a href="#tour_guide">Part 3</a>.
      With your partner, select the best algorithm from both of your notebooks to use.
    </p>

  <h3 id="tour_guide">Part 3: Robot Museum Tour Guide</h3>

    <p>
      Once you have trained a machine learning algorithm to recognize digits, you will use it on the robot to detect digits using the robot's camera. The robot's task will be to detect images in a museum (represented by a maze), and use the result to select which museum location to go to next. The waypoints corresponding to each digit will be provided by the instructors. The robot will use planning code from Project 3 to drive between the waypoints.
    </p>

    <p>The instructors will provide a list of digits and their corresponding waypoints.
      <strong>Not all digits will be represented.</strong>
      Here is an example waypoint course configuration, where the digit of interest is followed by a waypoint, in format <code>[x, y, theta]</code> (positions are in meters and angles are in radians):
    </p>

    <pre><code>0: [0, 0, 0]
3: [3, 2, -PI / 2]
5: [2, 0, PI / 2]
8: [0, 2, 0]</code></pre>

    <p>This configuration corresponds to the following map:</p>
    <span class="image main"><img src="/assets/images/p4/maze_ex.jpg" alt="" style="max-width:650px;"/></span>
    <p>The waypoints are labelled in blue circles, and correspond to the waypoints given in the course configuration. On the wall facing the given configuration, there will be a handwritten digit (as shown in the image). The digit tells the robot which waypoint to visit next. All waypoints in the configuration will have a handwritten digit at the corresponding map location.</p>

    <p>The robot will always start at <code>[0, 0, 0]</code>. A handwritten digit on the wall of the maze will tell the robot which waypoint to visit first. When the robot detects the digit <strong>&quot;0&quot;</strong>, it should return to the zero position, and stop execution (i.e. it should <i>not</i> travel back to the waypoint it detects at the origin). In the above example, the robot's trajectory should be: <strong>&quot;0&quot; &#8594; &quot;5&quot; &#8594; &quot;8&quot; &#8594; &quot;3&quot; &#8594; &quot;0&quot;</strong>.</p>

    <p>You will receive full points if the robot follows the path correctly as described by the configuration. You should print out the digit detected at each waypoint. You will not lose points for up to 1 incorrect detection. You must deal with the case where the robot detects a digit which does not correspond to a valid detection.</p>

    <h4 id="robot_setup">Robot Setup</h4>

    <p>You will use your code from Project 3 to generate plans between waypoints, and your model output from the Colab notebooks in <a href="#train_ml">Part 2</a> to detect digits. You can use the planning binary and classification model from either partner. Follow these steps to set up your robot:</p>

    <ol>
      <li>Upgrade Python's installer, Pip:<br/>
        <pre><code class="language-bash">pip install --upgrade pip</code></pre>
      </li>
      <li>Clone your team's repo onto the robot.</li>
      <li>Install the dependencies for the project:<br/>
        <pre><code class="language-bash">cd robot-tour-guide-f22-[TEAM]
pip install -r requirements.txt</code></pre>
      </li>
      <li>Get the path planning executable from Project 3. This file gets placed in the <code>build</code> directory of the Project 3 repository and is called <code>robot_plan_path</code>. Place this file in the <code>bin</code> folder in your Project 4 repository.</li>
      <li>Get the model from your Colab notebook. Place it in your repository. Update the variable <code>PATH_TO_MODEL</code> in the file <code>robot_tour_guide.py</code> to contain the path to the file.</li>
    </ol>

    <p>Now you are ready to start coding!</p>

    <h4 id="robot_code">Robot Code</h4>

    <p><strong>Before running your code, you must create a map and be properly localized within it.</strong> Follow the <a href="/mbot/mapping">localization instructions</a>.</p>

    <p>A number of helper functions have been created for you. You must follow the steps in <a href="#robot_setup">Robot Setup</a> before writing or running any code.</p>

    <p><strong>Robot Functions:</strong>
      The Robot helper allows you to drive the robot, plan to and execute a path, and turn to a goal. Use this functionality as follows:
    </p>
    <pre><code class="language-python">robot = Robot()  # This variable is defined for you in the template.
robot.plan_to_pose(x, y)    # Use this to drive to a goal location.
robot.turn_to_theta(theta)  # Use this to turn to a goal angle.</code></pre>

  <p><strong>Camera Functions:</strong>
    The camera helper looks for Post-It notes in the camera image, and returns a cropped and scaled image which is the correct size to pass through your classification algorithm. To use it, do:
  </p>
  <pre><code class="language-python">ch = CameraHandler()  # This variable is defined for you in the template.
frame = ch.get_image()   # Get the image of a digit from the camera.</code></pre>

  <p>If a digit is not detected in the frame, it will return <code class="language-python">None</code>. You should handle this case. To save the image to the folder <code>output</code>, pass <code class="language-python">save=True</code> to the above function. This might be useful for debugging.</p>

  <p>To perform prediction on the frame using your model, do:</p>
  <pre><code class="language-python">y_pred = model.predict([frame])[0]</code></pre>

</section>
